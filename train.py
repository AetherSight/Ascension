import os
import torch
import torch.optim as optim
import torch.nn.functional as F

from torch.utils.data import DataLoader
from torch.amp import autocast, GradScaler
from torch.optim.lr_scheduler import CosineAnnealingLR
from tqdm import tqdm

from lib import SupConClothingDataset, EmbeddingModel, SupConLoss, PartialToWholeLoss, ClothingTransform
from evaluate import evaluate_real_world_images


def train(
    data_root: str, 
    batch_size: int = 16, 
    target_batch: int = 128, 
    epochs: int = 50, 
    warmup_epochs: int = 5, 
    lr: float = 3e-4, 
    save_dir: str = "checkpoints",
    resume_path: str | None = None,
    # è¯„ä¼°ç›¸å…³å‚æ•°
    eval_gallery_root: str | None = None,  # gallery è·¯å¾„
    eval_image_paths: list[str] | None = None,  # æµ‹è¯•å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    eval_top_k: int = 5,  # è¯„ä¼°æ—¶è¾“å‡ºçš„ top-k
):
    config = {
        "data_root": data_root,
        "batch_size": batch_size,
        "target_batch": target_batch,
        "epochs": epochs,
        "warmup_epochs": warmup_epochs,
        "lr": lr,
        "save_dir": save_dir,
        "model_name": "tf_efficientnetv2_m",
        "temperature": 0.1,
        "use_partial_loss": True,
        "partial_loss_weight": 0.5,
        "num_patches": 4,
        "patch_size": 256
    }

    accumulation_steps = max(1, config["target_batch"] // config["batch_size"])
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    os.makedirs(config["save_dir"], exist_ok=True)

    # Dataset & Loader
    train_ds = SupConClothingDataset(
        config["data_root"], 
        transform=ClothingTransform(train=True)
    )

    train_loader = DataLoader(
        train_ds,
        batch_size=config["batch_size"],
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        drop_last=True
    )

    # Model
    model = EmbeddingModel(config["model_name"], use_local_features=True).to(device)
    criterion = SupConLoss(temperature=config["temperature"])
    partial_criterion = PartialToWholeLoss(temperature=config["temperature"])
    optimizer = optim.AdamW(model.parameters(), lr=config["lr"], weight_decay=1e-4)
    main_scheduler = CosineAnnealingLR(
        optimizer,
        T_max=config["epochs"] - config["warmup_epochs"]
    )
    scaler = GradScaler("cuda")

    start_epoch = 1
    best_loss = float("inf")

    # =========================
    # Resume logic
    # =========================
    if resume_path is not None:
        ckpt = torch.load(resume_path, map_location="cpu")
        model.load_state_dict(ckpt["model"], strict=True)
        
        start_epoch = ckpt["epoch"] + 1
        best_loss = ckpt.get("loss", best_loss)
        
        if "optimizer" in ckpt:
            optimizer.load_state_dict(ckpt["optimizer"])
        if "scheduler" in ckpt:
            main_scheduler.load_state_dict(ckpt["scheduler"])
        else:
            # Old checkpoint without scheduler state, manually restore
            # Scheduler starts after warmup, so steps = epoch - warmup_epochs
            if start_epoch > config["warmup_epochs"]:
                scheduler_steps = ckpt["epoch"] - config["warmup_epochs"]
                for _ in range(scheduler_steps):
                    main_scheduler.step()
                print(f"âš ï¸  Old checkpoint detected, manually restored scheduler to step {scheduler_steps}")

        print(f"ğŸ” Resume SupCon from epoch {ckpt['epoch']} â†’ {start_epoch}")
        print(f"ğŸ“Š Current LR: {optimizer.param_groups[0]['lr']:.2e}")

    print(
        f"ğŸš€ Physical Batch: {config['batch_size']} | "
        f"Acc steps: {accumulation_steps} | "
        f"Effective Batch: {config['batch_size'] * accumulation_steps}"
    )

    # =========================
    # Training loop
    # =========================
    for epoch in range(start_epoch, config["epochs"] + 1):

        # Warmupï¼ˆåªåœ¨çœŸå®å‰å‡ è½®ï¼‰
        if epoch <= config["warmup_epochs"]:
            curr_lr = config["lr"] * (epoch / config["warmup_epochs"])
            for pg in optimizer.param_groups:
                pg["lr"] = curr_lr

        model.train()
        total_loss = 0.0
        optimizer.zero_grad(set_to_none=True)

        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{config['epochs']}")

        for i, (views, labels) in enumerate(pbar):
            bsz = views.size(0)
            views = views.view(-1, *views.shape[2:]).to(device)
            labels = labels.to(device)

            with autocast("cuda"):
                # æå–å…¨å±€ç‰¹å¾
                global_emb, _ = model(views, return_local=False)
                global_emb = F.normalize(global_emb, dim=1)
                
                # å…¨å±€å¯¹æ¯”æŸå¤±
                global_loss = criterion(
                    global_emb.view(bsz, 2, -1),
                    labels
                )
                
                # éƒ¨åˆ†åˆ°æ•´ä½“å¯¹æ¯”æŸå¤±
                partial_loss = 0.0
                if config.get("use_partial_loss", True) and (i % 2 == 0):  # æ¯2æ­¥è®¡ç®—ä¸€æ¬¡ï¼Œå‡å°‘è®¡ç®—é‡
                    # ä»åŸå§‹å®Œæ•´å›¾åƒæå–patchç‰¹å¾
                    # viewsæ˜¯å¢å¼ºåçš„ï¼Œæˆ‘ä»¬éœ€è¦ä»åŸå§‹batchä¸­æå–
                    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä»viewsä¸­æå–ï¼ˆè™½ç„¶å·²ç»å¢å¼ºï¼Œä½†ä»ç„¶æ˜¯å±€éƒ¨åˆ°æ•´ä½“çš„å…³ç³»ï¼‰
                    patch_emb = model.extract_patch_features(
                        views.view(bsz, 2, *views.shape[1:])[:, 0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªview
                        patch_size=config.get("patch_size", 256),
                        num_patches=config.get("num_patches", 4)
                    )
                    
                    # è®¡ç®—éƒ¨åˆ†åˆ°æ•´ä½“æŸå¤±ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªviewçš„å…¨å±€ç‰¹å¾ï¼‰
                    global_for_partial = global_emb.view(bsz, 2, -1)[:, 0]  # [B, D]
                    labels_for_partial = labels
                    partial_loss = partial_criterion(
                        global_for_partial,
                        patch_emb,
                        labels_for_partial,
                        num_patches=config.get("num_patches", 4)
                    )
                
                # æ€»æŸå¤±
                loss_weight = config.get("partial_loss_weight", 0.5)
                loss = (global_loss + loss_weight * partial_loss) / accumulation_steps

            scaler.scale(loss).backward()

            if (i + 1) % accumulation_steps == 0:
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad(set_to_none=True)

            total_loss += loss.item() * accumulation_steps
            pbar.set_postfix({
                "loss": f"{loss.item() * accumulation_steps:.4f}",
                "lr": f"{optimizer.param_groups[0]['lr']:.2e}"
            })

        if epoch > config["warmup_epochs"]:
            main_scheduler.step()

        avg_loss = total_loss / len(train_loader)

        checkpoint = {
            "model": model.state_dict(),
            "optimizer": optimizer.state_dict(),
            "scheduler": main_scheduler.state_dict(),
            "class_names": train_ds.class_names,
            "epoch": epoch,
            "loss": avg_loss
        }

        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save(
                checkpoint,
                os.path.join(config["save_dir"], "best_supcon.pth")
            )

        if epoch % 5 == 0:
            torch.save(
                checkpoint,
                os.path.join(
                    config["save_dir"], f"epoch_{epoch}_supcon.pth"
                )
            )
            
            # æ¯5è½®è¯„ä¼°çœŸå®å›¾ç‰‡æ•ˆæœ
            if eval_gallery_root and eval_image_paths:
                print(f"\n{'='*60}")
                print(f"ğŸ“Š Epoch {epoch} - è¯„ä¼°çœŸå®å›¾ç‰‡æ•ˆæœ")
                print(f"{'='*60}")
                
                try:
                    cache_path = os.path.join(config["save_dir"], f"epoch_{epoch}_gallery_cache.pth")
                    results = evaluate_real_world_images(
                        model=model,
                        gallery_root=eval_gallery_root,
                        image_paths=eval_image_paths,
                        device=device,
                        top_k=eval_top_k,
                        cache_path=cache_path
                    )
                    
                    for img_path, top_results in results:
                        print(f"\n[Query] {os.path.basename(img_path)}")
                        for i, (label, score) in enumerate(top_results, 1):
                            print(f"  Top-{i}: {label} (cos={score:.4f})")
                    
                    print(f"{'='*60}\n")
                except Exception as e:
                    print(f"âš ï¸  è¯„ä¼°å¤±è´¥: {e}\n")

    print("âœ… SupCon è®­ç»ƒå®Œæˆ")


if __name__ == "__main__":
    # æµ‹è¯•å›¾ç‰‡è·¯å¾„ï¼ˆå¯æ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰
    test_images = [
        r"S:\FFXIV_train_test\a.JPG",
        r"S:\FFXIV_train_test\b.JPG",
        r"S:\FFXIV_train_test\c.JPG",
        r"S:\FFXIV_train_test\d.JPG",
        r"S:\FFXIV_train_test\e.JPG",
        r"S:\FFXIV_train_test\1.JPG",
        r"S:\FFXIV_train_test\1_back.JPG",
        r"S:\FFXIV_train_test\1_front.JPG",
        r"S:\FFXIV_train_test\1_front.png",
        r"S:\FFXIV_train_test\1_side.JPG",
        r"S:\FFXIV_train_test\1_part.JPG",
        r"S:\FFXIV_train_test\2.JPG",
        r"S:\FFXIV_train_test\4.JPG",
        r"S:\FFXIV_train_test\4_2.JPG",
        r"S:\FFXIV_train_test\5.JPG",
        r"S:\FFXIV_train_test\6.JPG",
        r"S:\FFXIV_train_test\unknown_1.JPG",
        r"S:\FFXIV_train_test\é¬¼å¸ˆ.png",
        r"S:\FFXIV_train_test\ç‰éŸ¦äºšç“¦å¡”å¼ºè¢­çŸ­è¡£.png",
        r"S:\FFXIV_train_test\download.png",
    ]
    
    train(
        data_root="S:\\FFXIV_train_dataset",
        batch_size=16,
        target_batch=128,
        epochs=70,
        warmup_epochs=5,
        lr=3e-4,
        save_dir="checkpoints",
        # è¯„ä¼°é…ç½®ï¼ˆè®¾ç½®ä¸º None å¯ç¦ç”¨è¯„ä¼°ï¼‰
        eval_gallery_root=r"S:\FFXIV_train_dataset",
        eval_image_paths=test_images,
        eval_top_k=5,
    )
